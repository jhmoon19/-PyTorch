{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7965eb7a",
   "metadata": {},
   "source": [
    "# 단어 임베딩 \n",
    "## 코사인 유사도 \n",
    "- 벡터 공간에서 유사도를 나타내는 방법 \n",
    "- 원핫 인코딩으로 표현한 두 벡터의 코사인 유사도는 항상 0\n",
    "- --> 밀집 벡터 필요 --> \"임베딩 기법\"\n",
    "- 모든 실수 차원으로 원하는 차원 수만큼 단어 표현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "285e365f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.7396)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x1 = torch.FloatTensor([1,2,3,4])\n",
    "x2 = torch.FloatTensor([1,4,2,1])\n",
    "\n",
    "print(torch.cosine_similarity(x1, x2, dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba47002d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "# 원핫인코딩으로 코사인 유사도 계산하면 안되는 이유\n",
    "word1 = torch.FloatTensor([0,1,0,0,0])\n",
    "word2 = torch.FloatTensor([0,0,0,1,0])\n",
    "\n",
    "print(torch.cosine_similarity(word1, word2, dim=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac57bcff",
   "metadata": {},
   "source": [
    "## 임베딩 조회 (embedding look up)\n",
    "- \"행렬 곱셈\": 원핫인코딩된 단어들과 임베딩 행렬 간의 곱셈\n",
    "- --> 오차 역전파 가능--> 임베딩 표현된 문장을 목적에 맞게 훈련 가능\n",
    "- torch.nn.Embedding 으로 임베딩 층 구현 가능\n",
    "- 임베딩 층의 입력은 무조건 LongTensor 타입 인덱스여야 함. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbaf00ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  5.,  7.],\n",
      "        [ 2.,  1.,  8.],\n",
      "        [ 6.,  1., 10.]])\n",
      "\n",
      "tensor([[ 1.,  5.,  7.],\n",
      "        [ 2.,  1.,  8.],\n",
      "        [ 6.,  1., 10.]], grad_fn=<EmbeddingBackward>)\n"
     ]
    }
   ],
   "source": [
    "tokens = \"We are going to watch Avengers End Game\".split()\n",
    "new_sent = \"We are Avengers\".split()\n",
    "vocab = {token:i for i,token in enumerate(tokens)}\n",
    "\n",
    "# 임베딩 층 사용하지 않을 경우 임베딩 기법 구현\n",
    "embedding = torch.FloatTensor([[1,5,7],\n",
    "                              [2,1,8],\n",
    "                              [1,4,5],\n",
    "                              [4,1,1],\n",
    "                              [1,8,9],\n",
    "                              [6,1,10],\n",
    "                              [3,2,2],\n",
    "                              [1,5,4]])\n",
    "\n",
    "idxes = torch.LongTensor([vocab[token] for token in new_sent])\n",
    "print(embedding[idxes, :])\n",
    "print()\n",
    "\n",
    "# 파이토치에서 사용하는 방법\n",
    "import torch.nn as nn\n",
    "\n",
    "embedding_layer = nn.Embedding(num_embeddings=len(vocab),\n",
    "                              embedding_dim=3,\n",
    "                              _weight=embedding)\n",
    "\n",
    "# 해당하는 index 조회\n",
    "print(embedding_layer(idxes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124952cb",
   "metadata": {},
   "source": [
    "## Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7044dd24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\answl\\anaconda3\\envs\\nlp\\lib\\site-packages\\ipykernel_launcher.py:19: DeprecationWarning: Call to deprecated `init_sims` (Gensim 4.0.0 implemented internal optimizations that make calls to init_sims() unnecessary. init_sims() is now obsoleted and will be completely removed in future versions. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30382, 100)\n"
     ]
    }
   ],
   "source": [
    "from konlpy.tag import Mecab\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "\n",
    "# 품사정보를 \"(단어)/(품사정보)\" 처럼 함께 저장하기위해 tokenizer 함수를 정의\n",
    "mecab = Mecab('C:/mecab/mecab-ko-dic')\n",
    "tokenizer = lambda x: ['/'.join((token.lower(), pos.lower())) for (token, pos) in mecab.pos(x)]\n",
    "\n",
    "with open(\"./data/nsmc/ratings.txt\", encoding='utf8') as file:\n",
    "    # 행단위로 데이터 분리. 첫 행은 header 제외\n",
    "    raw_data = file.read().splitlines()[1:]\n",
    "    # 텍스트 데이터만 사용 \n",
    "    data = [line.split('\\t')[1] for line in raw_data]\n",
    "    # 토큰화 진행 \n",
    "    data = [tokenizer(sent) for sent in data]\n",
    "    \n",
    "model = Word2Vec(sentences=data, vector_size=100, window=5, min_count=3, sg=1)\n",
    "\n",
    "# 훈련 완료 후 불필요한 메모리 제거\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# 단어 임베딩 행렬의 크기\n",
    "print(model.wv.vectors.shape)\n",
    "\n",
    "# 모델 저장: 파일의 첫번째 줄에는 임베딩 행렬의 크기가 적혀있다.\n",
    "model.wv.save_word2vec_format('./word2vec.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdff0860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e40af589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.word2vec.Word2Vec at 0x18a8e632788>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eecb64a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x18a92959d48>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7a6b8c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-4.22248952e-02,  9.41601768e-02,  4.21626261e-03, ...,\n",
       "        -1.38073772e-01,  2.94470266e-02,  1.48032997e-02],\n",
       "       [-5.42283878e-02,  7.47420564e-02, -9.44374874e-03, ...,\n",
       "        -1.64438054e-01, -1.51937391e-04, -6.72569079e-03],\n",
       "       [ 5.28738229e-03,  9.87587348e-02, -1.14748582e-01, ...,\n",
       "        -7.00663701e-02,  4.04933915e-02, -6.67541921e-02],\n",
       "       ...,\n",
       "       [-1.08063646e-01,  1.15178891e-01,  8.33605900e-02, ...,\n",
       "        -1.27238229e-01, -1.66832078e-02,  7.10420385e-02],\n",
       "       [-3.18642035e-02,  1.09030612e-01,  1.88518986e-02, ...,\n",
       "        -1.64858624e-01, -9.71087217e-02,  1.16480373e-01],\n",
       "       [-1.00412704e-02,  2.07997292e-01,  4.18835543e-02, ...,\n",
       "        -1.76711723e-01, -5.25666922e-02,  1.60133615e-01]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af50840",
   "metadata": {},
   "source": [
    "## 단어 간 유사도 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c6edc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similarity(여배우, 배우) = 0.79\n"
     ]
    }
   ],
   "source": [
    "# 1. '여배우'와 '배우'의 유사도\n",
    "sim1 = model.wv.similarity(*tokenizer(\"여배우 배우\"))\n",
    "print(\"similarity(여배우, 배우) = {:.2f}\".format(sim1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50a329f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전개/nng = 0.83\n",
      "시나리오/nng = 0.82\n",
      "내용/nng = 0.81\n",
      "줄거리/nng = 0.78\n",
      "설정/nng = 0.77\n"
     ]
    }
   ],
   "source": [
    "# 2. '스토리'와 가장 유사한 단어 Top 5\n",
    "sim2 = model.wv.most_similar(tokenizer('스토리'), topn=5)\n",
    "\n",
    "for t,s in sim2:\n",
    "    print(\"{} = {:.2f}\".format(t,s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7504f34b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('여배우/nng', 0.7906150817871094)]\n"
     ]
    }
   ],
   "source": [
    "# 3. 벡터 연산: '남자배우' - '남자' = '연기자'\n",
    "sim3 = model.wv.most_similar(positive=tokenizer('남자배우'),\n",
    "                            negative=tokenizer('남자'),\n",
    "                            topn = 1)\n",
    "print(sim3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f876005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('여배우/nng', 0.7906150817871094), ('출연진/nng', 0.7714549899101257), ('연기자/nng', 0.7703227400779724), ('조연/nng', 0.7573984265327454), ('명배우/nng', 0.7529410123825073)]\n"
     ]
    }
   ],
   "source": [
    "sim3 = model.wv.most_similar(positive=tokenizer('남자배우'),\n",
    "                            negative=tokenizer('남자'),\n",
    "                            topn = 5)\n",
    "print(sim3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "baaa1797",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/30382 [00:00<?, ?it/s]Skipping token b'30382' with 1-dimensional vector [b'100']; likely a header\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 30382/30382 [00:05<00:00, 5898.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([30369, 100])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-6.2962e-02,  1.7045e-01,  6.8156e-02,  1.2706e-01, -1.1174e-01,\n",
       "         -1.7718e-01,  5.2652e-02,  2.2250e-01, -4.3966e-02, -7.6643e-02,\n",
       "          1.7943e-02, -8.5420e-02,  1.0086e-02,  2.1237e-01,  6.9371e-02,\n",
       "         -3.0939e-02, -1.2076e-01, -7.4392e-02,  1.0391e-01, -1.2644e-01,\n",
       "          1.4588e-01,  2.3058e-02,  8.4698e-02,  5.6798e-02,  9.5416e-02,\n",
       "          9.2290e-03, -1.8434e-01,  5.8887e-02, -1.4722e-01,  2.7922e-02,\n",
       "          6.0077e-02, -1.1426e-01,  5.2521e-02, -4.5747e-02, -1.3291e-01,\n",
       "          1.2034e-01,  4.6845e-02, -2.4517e-05,  4.8735e-02,  1.7887e-02,\n",
       "          1.9254e-02, -7.3278e-03, -1.8899e-01, -8.1516e-02, -4.3002e-02,\n",
       "         -1.2576e-01, -1.0177e-01, -1.0308e-01,  2.1195e-01,  4.9919e-02,\n",
       "          7.3218e-02,  7.2246e-03, -4.4953e-03,  4.6088e-02,  1.4022e-01,\n",
       "         -1.9702e-02,  3.8092e-03, -6.4428e-02,  4.4049e-02,  1.0571e-01,\n",
       "          1.5873e-02, -3.6440e-02,  3.0050e-02,  1.0486e-02, -6.0427e-02,\n",
       "          1.3021e-01,  4.7938e-03,  7.9807e-02, -1.1013e-01,  1.9609e-01,\n",
       "         -1.4691e-01,  1.3159e-01, -8.6750e-02, -9.4466e-03, -8.4158e-02,\n",
       "          6.6482e-02,  6.0475e-02,  2.9014e-02, -9.0321e-02,  4.5027e-02,\n",
       "         -1.3903e-02,  1.0490e-01,  2.8262e-02,  1.3300e-01, -1.3069e-01,\n",
       "         -2.5965e-02,  8.7430e-02,  1.0042e-01,  8.0203e-02,  1.1364e-01,\n",
       "          4.4649e-02, -1.0991e-01, -1.8126e-02, -1.5346e-01,  3.2230e-01,\n",
       "          2.1955e-02, -1.2083e-01, -9.0790e-02,  2.4111e-02,  4.0963e-03]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gensim\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.legacy.data import Field\n",
    "from torchtext.legacy.data import TabularDataset\n",
    "from torchtext.legacy.data import Iterator\n",
    "from torchtext.vocab import Vectors\n",
    "from konlpy.tag import Mecab\n",
    "\n",
    "mecab = Mecab('C:/mecab/mecab-ko-dic')\n",
    "tokenizer = lambda x: ['/'.join((token.lower(), pos.lower()))\n",
    "                      for token, pos in mecab.pos(x)]\n",
    "\n",
    "# 필드 정의\n",
    "TEXT = Field(sequential=True,\n",
    "            use_vocab=True,\n",
    "            tokenize=tokenizer,\n",
    "            lower=True,\n",
    "            batch_first=True)\n",
    "\n",
    "LABEL = Field(sequential=True,\n",
    "             use_vocab=False,\n",
    "             preprocessing=lambda x: int(*x),\n",
    "             batch_first=True,\n",
    "             is_target=True)\n",
    "\n",
    "ID = Field(sequential=False,\n",
    "          use_vocab=False,\n",
    "          is_target=False)\n",
    "\n",
    "dataset = TabularDataset(path='./data/nsmc/ratings.txt',\n",
    "                        format='tsv',\n",
    "                        fields=[('id', ID), ('text', TEXT), ('label', LABEL)],\n",
    "                        skip_header=True)\n",
    "\n",
    "# 훈련된 임베딩 행렬 사용 위해 Vectors 객체 만들어서 TEXT 필드로 전달\n",
    "# 파일 내 첫번째 행은 임베딩 행렬 크기기 때문에 무시하게 된다.\n",
    "vectors = Vectors(name='word2vec.pt')\n",
    "\n",
    "# 생성한 vector 객체를 단어장을 만들면서 필드로 전달\n",
    "TEXT.build_vocab(dataset, min_freq=3, vectors=vectors)\n",
    "\n",
    "# 필드에 <unk>과 <pad> 토큰을 포함한 임베딩 행렬로 구성됨\n",
    "print(TEXT.vocab.vectors.size())\n",
    "\n",
    "# 임베딩 층을 필드에 내장된 임베딩 행렬로 초기화\n",
    "# freeze 비활성해야 계속 학습 가능\n",
    "embedding = nn.Embedding.from_pretrained(TEXT.vocab.vectors, freeze=False)\n",
    "embedding(torch.LongTensor([2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eeb2c974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.legacy.data.field.Field at 0x243c195cd88>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7c8da47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.legacy.data.dataset.TabularDataset at 0x243c195c948>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "18a24223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.vocab.Vectors at 0x243c195ca08>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d00d455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.vocab.Vocab at 0x243c195cac8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f83aa9ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [-0.0630,  0.1705,  0.0682,  ..., -0.0908,  0.0241,  0.0041],\n",
       "        ...,\n",
       "        [-0.0825,  0.1206,  0.0799,  ..., -0.0981, -0.0391,  0.1410],\n",
       "        [-0.1366,  0.0826,  0.0267,  ..., -0.1901, -0.0620,  0.1848],\n",
       "        [-0.0333,  0.1729, -0.0055,  ..., -0.1404, -0.0786,  0.1420]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7e57076",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30369, 100])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT.vocab.vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89df78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
