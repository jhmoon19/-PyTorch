{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38c0cb52",
   "metadata": {},
   "source": [
    "# 순환 신경망\n",
    "## 순환 신경망의 내부 구조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "949b777b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CustomRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, batch_first=True):\n",
    "        super(CustomRNN, self).__init__()\n",
    "        \n",
    "        # 선형결합에 사용할 학습가능한 매개변수 생성\n",
    "        self.weight_xh, self.weight_hh, self.bias = \\\n",
    "            self.init_weight(input_size, hidden_size)\n",
    "        \n",
    "        # 필요 정보 저장\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_first = batch_first\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        \"\"\"\n",
    "        rnn_cell 구동하기 위해 inputs의 크기가 (T,B,E) 형태 되야함.\n",
    "        - T: 시퀀스 총 길이\n",
    "        - B: 미니배치 크기\n",
    "        - E: 입력층 크기\n",
    "        \"\"\"\n",
    "        if self.batch_first:\n",
    "            # 첫번째 차원이 미니배치 크기인 경우 전치연산으로 바꿔줌 \n",
    "            inputs = inputs.transpose(0,1)\n",
    "            \n",
    "        seqlen, batch_size, _ = inputs.size()\n",
    "        \n",
    "        # 0 time-step에서 은닉층 값을 0으로 초기화\n",
    "        hidden = self.init_hidden(batch_size, self.hidden_size)\n",
    "        \n",
    "        # output에 은닉층의 출력값 저장\n",
    "        output = []\n",
    "        \n",
    "        # 시퀀스의 총 길이만큼 순방향 전파 진행\n",
    "        for i in range(seqlen):\n",
    "            hidden = self.rnn_cell(inputs[i], hidden)\n",
    "            output.append(hidden)\n",
    "        \n",
    "        output = torch.stack(output)\n",
    "        \n",
    "        if self.batch_first:\n",
    "            output = output.transpose(0,1)\n",
    "            \n",
    "        # 모든 타임스텝의 은닉층 출력값과 마지막 타임스텝의 은닉층 출력값을 각각 반환\n",
    "        return output, hidden\n",
    "    \n",
    "    def rnn_cell(self, x, h):\n",
    "        \"\"\" RNN Cell \"\"\"\n",
    "        h = x.mm(self.weight_xh.t()) + h.mm(self.weight_hh.t()) + self.bias\n",
    "        return torch.tanh(h)\n",
    "    \n",
    "    def init_hidden(self, batch_size, hidden_size):\n",
    "        \"\"\" 0 타입스텝에서 은닉층 초기화 \"\"\"\n",
    "        return torch.zeros(batch_size, hidden_size)\n",
    "    \n",
    "    def init_weight(self, input_size, hidden_size):\n",
    "        \"\"\" rnn_cell 의 선형결합을 위한 초기값 \"\"\"\n",
    "        weight_xh = torch.randn(hidden_size, input_size).requires_grad_()\n",
    "        weight_hh = torch.randn(hidden_size, hidden_size).requires_grad_()\n",
    "        bias = torch.zeors(1, hidden_size).requires_grad_()\n",
    "        \n",
    "        return weight_xh, weight_hh, bias\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f626193",
   "metadata": {},
   "source": [
    "## 순환 신경망의 단점 : 장기 의존성 문제 (Long-Term Dependency)\n",
    "- 타임스텝이 길어질수록 예전에 있던 정보를 기억하지 못한다.\n",
    "- --> 미분값이 0에 수렴하여 역전파가 앞단까지 전달되지 않는다.\n",
    "- ex. \"나는 한국 사람이고, **중국 칭다오에 아주 오래 살다가** 지금은 서울에 살고 있어. ... 어쨎든, 미국으로 유학을 다녀왔지만 영어는 잘 못해, 하지만 **중국어는 잘해!**\"\n",
    "- \"경사 소실\": 긴 시퀀스의 경우 미분값이 0에 가까워져 매개변수에 반영되지 않음.\n",
    "\n",
    "## LSTM (Long Short-term Memory)\n",
    "- RNN Cell 안에 별도의 Cell State 변수 만들어 경사 소실 문제 피하려 함.\n",
    "- Cell State는 각 타임스텝에서 기억할 정보와 망각할 정보를 처리, 향후 경사를 잘 전달할 수 있게 만드는 통로 역할을 함. (= 컨베이어 벨트)\n",
    "- 많은 매개변수 필요함. \n",
    "\n",
    "## GRU (Gated Recurrent Unit)\n",
    "- LSTM 보다 좀더 간단하고 비슷한 성능 냄.\n",
    "- 0~1 사이 게이트가 정보 유지할지 잊을지 결정.\n",
    "\n",
    "아직까지는 GRU보단 LSTM이 더 많이 쓰이고 있음. 취향 차이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6df28205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN(5, 10, batch_first=True)\n",
      "LSTM(5, 10, batch_first=True)\n",
      "GRU(5, 10, batch_first=True)\n"
     ]
    }
   ],
   "source": [
    "# RNN, LSTM, GRU 호출 방법\n",
    "\n",
    "rnn_layer = nn.RNN(input_size=5, hidden_size=10, batch_first=True)\n",
    "print(rnn_layer)\n",
    "\n",
    "rnn_layer = nn.LSTM(input_size=5, hidden_size=10, batch_first=True)\n",
    "print(rnn_layer)\n",
    "\n",
    "rnn_layer = nn.GRU(input_size=5, hidden_size=10, batch_first=True)\n",
    "print(rnn_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e1ec28",
   "metadata": {},
   "source": [
    "## 간단한 순환 신경망 예제\n",
    "- \"We are going to watch Avengers End Game\" 출력하는 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b9cdf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[01/151] 2.3034 \n",
      "We Avengers watch are going watch watch Avengers\n",
      "\n",
      "[31/151] 1.9172 \n",
      "We are Avengers going are Avengers End Game\n",
      "\n",
      "[61/151] 1.5057 \n",
      "We are going going watch Avengers End Game\n",
      "\n",
      "[91/151] 1.0342 \n",
      "We are going to watch Avengers End Game\n",
      "\n",
      "[121/151] 0.6438 \n",
      "We are going to watch Avengers End Game\n",
      "\n",
      "[151/151] 0.3932 \n",
      "We are going to watch Avengers End Game\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "torch.manual_seed(70)\n",
    "\n",
    "sentence = \"We are going to watch Avengers End Game\".split()\n",
    "vocab = {token: i for i, token in enumerate(sentence, 1)}\n",
    "vocab['<unk>'] = 0\n",
    "\n",
    "# 수치화된 데이터를 단어로 바꾸기 위한 사전 \n",
    "rev_vocab = {v:k for k,v in vocab.items()}\n",
    "\n",
    "# 수치화된 데이터를 단어로 전환하는 함수\n",
    "decode = lambda y: [rev_vocab.get(x) for x in y]\n",
    "\n",
    "def construct_data(sentence, vocab):\n",
    "    \"\"\"\n",
    "    (input, target) 쌍으로 데이터 생성\n",
    "    - 최종 형태 (수치화된 단어 쌍):\n",
    "      [(We, are), (are, going), (going, to), (to, watch),\n",
    "          (watch, Avengers), (Avengers, End), (End, Game)]\n",
    "    \"\"\"\n",
    "    numericalize = lambda x: vocab.get(x) if vocab.get(x) is not None else 0\n",
    "    totensor = lambda x: torch.LongTensor(x)\n",
    "    idxes = [numericalize(token) for token in sentence]\n",
    "    x,t = idxes[:-1], idxes[1:]\n",
    "    \n",
    "    return totensor(x).unsqueeze(0), totensor(t).unsqueeze(0)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    \"\"\" 예제 문장을 출력하는 모델 \"\"\"\n",
    "    def __init__(self, vocab_size, input_size, hidden_size, batch_first=True):\n",
    "        super(Net, self).__init__()\n",
    "        \"\"\"\n",
    "        vocab_size : 단어장 크기\n",
    "        input_size : 임베딩 크기 (RNN 입력층 크기)\n",
    "        hidden_size : RNN 은닉층 크기\n",
    "        \"\"\"\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                            embedding_dim=input_size)\n",
    "        self.rnn_layer = nn.RNN(input_size, hidden_size,\n",
    "                               batch_first = batch_first)\n",
    "        self.linear = nn.Linear(hidden_size, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        텐서 크기 변화 위한 문자 설명\n",
    "        - V: 단어장 크기\n",
    "        - T: 시퀀스 총 길이\n",
    "        - B: 미니배치 크기\n",
    "        - E: 임베딩 크기 (RNN 입력층 크기)\n",
    "        - D: RNN 은닉층 크기\n",
    "        \"\"\"\n",
    "        \n",
    "        # 1. embedding 층 통과해서 분산표상 방식으로 단어 표현\n",
    "        # 크기변화: (B,T) > (B,T,D)\n",
    "        output = self.embedding_layer(x)\n",
    "        \n",
    "        # 2. RNN 층\n",
    "        # 크기변화: (B,T,D) > output (B,T,D) / hidden (1,B,D)\n",
    "        output, hidden = self.rnn_layer(output)\n",
    "        \n",
    "        # 3. 최종 출력층\n",
    "        # 크기변화: (B,T,D) > (B,T,V)\n",
    "        output = self.linear(output)\n",
    "        \n",
    "        # 4. 모델 출력:\n",
    "        # 크기변화: (B,T,V) > (B*T, V)\n",
    "        return output.view(-1, output.size(2))\n",
    "    \n",
    "\n",
    "# 데이터 생성\n",
    "x, t = construct_data(sentence, vocab)\n",
    "\n",
    "# 모델 생성을 위한 하이퍼파라미터 설정\n",
    "vocab_size = len(vocab)  # 임베딩 층, 최종 출력층에 사용될 단어장 크기\n",
    "input_size = 5   # 임베딩 차원 크기(RNN 입력 차원 크기)\n",
    "hidden_size = 20 # RNN 은닉층 크기\n",
    "\n",
    "# 모델 생성\n",
    "model = Net(vocab_size, input_size, hidden_size, batch_first=True)\n",
    "\n",
    "# 손실함수 정의 \n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "\n",
    "# 옵티마이저 정의\n",
    "optimizer = optim.Adam(params=model.parameters())\n",
    "\n",
    "# 훈련 시작\n",
    "for step in range(151):\n",
    "    # 1) 경사 초기화\n",
    "    optimizer.zero_grad()\n",
    "    # 2) 순방향 전파\n",
    "    output = model(x)\n",
    "    # 3) 손실값 계산\n",
    "    loss = loss_function(output, t.view(-1))\n",
    "    # 4) 역방향 전파\n",
    "    loss.backward()\n",
    "    # 5) 매개변수 업데이트\n",
    "    optimizer.step()\n",
    "    # 기록 \n",
    "    if step % 30 == 0:\n",
    "        print(\"[{:02d}/151] {:.4f} \".format(step+1, loss))\n",
    "        pred = output.softmax(-1).argmax(-1).tolist()\n",
    "        print(\" \".join(['We'] + decode(pred)))\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b873c249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'We': 1,\n",
       " 'are': 2,\n",
       " 'going': 3,\n",
       " 'to': 4,\n",
       " 'watch': 5,\n",
       " 'Avengers': 6,\n",
       " 'End': 7,\n",
       " 'Game': 8,\n",
       " '<unk>': 0}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "925a9b79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'We',\n",
       " 2: 'are',\n",
       " 3: 'going',\n",
       " 4: 'to',\n",
       " 5: 'watch',\n",
       " 6: 'Avengers',\n",
       " 7: 'End',\n",
       " 8: 'Game',\n",
       " 0: '<unk>'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8540c8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.7617, -0.6662,  2.6440,  0.3793, -0.8535,  0.7474,  0.9093, -0.5351,\n",
       "         -0.6034],\n",
       "        [-0.6160, -0.6983,  0.0350,  2.6441,  0.5980, -0.9655, -0.3289,  1.0526,\n",
       "         -0.6033],\n",
       "        [-0.5833, -0.7808, -0.8670,  0.5197,  2.4368, -0.2169, -2.5131, -0.3115,\n",
       "          0.8703],\n",
       "        [-0.8453, -0.5904,  0.2934, -0.7246, -0.4353,  2.7860,  0.3800, -2.3972,\n",
       "          0.1200],\n",
       "        [-0.6625, -0.5480,  1.3101, -0.0367, -1.8888,  1.1051,  3.3165,  0.1471,\n",
       "         -0.4979],\n",
       "        [-0.3904, -0.3850, -0.2528,  1.1922,  0.3245, -1.6094,  0.4992,  3.2076,\n",
       "          0.9398],\n",
       "        [-1.7164, -0.6710, -0.5265, -0.3158,  0.7102, -0.2211, -0.9152,  0.5260,\n",
       "          2.9876]], grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "155000ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1387, 0.1354, 0.6413, 0.0644, 0.0238, 0.0897, 0.0723, 0.0184, 0.0198],\n",
       "        [0.1604, 0.1311, 0.0472, 0.6202, 0.1016, 0.0162, 0.0209, 0.0900, 0.0198],\n",
       "        [0.1658, 0.1208, 0.0192, 0.0741, 0.6390, 0.0342, 0.0024, 0.0230, 0.0865],\n",
       "        [0.1276, 0.1461, 0.0611, 0.0214, 0.0362, 0.6890, 0.0426, 0.0029, 0.0408],\n",
       "        [0.1531, 0.1524, 0.1689, 0.0425, 0.0085, 0.1283, 0.8023, 0.0364, 0.0220],\n",
       "        [0.2010, 0.1794, 0.0354, 0.1452, 0.0773, 0.0085, 0.0479, 0.7763, 0.0927],\n",
       "        [0.0534, 0.1348, 0.0269, 0.0321, 0.1137, 0.0341, 0.0117, 0.0531, 0.7184]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.softmax(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a31d07a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0206, 0.0227, 0.6208, 0.0645, 0.0188, 0.0932, 0.1095, 0.0258, 0.0241],\n",
       "        [0.0240, 0.0221, 0.0461, 0.6261, 0.0809, 0.0169, 0.0320, 0.1275, 0.0243],\n",
       "        [0.0301, 0.0247, 0.0226, 0.0906, 0.6162, 0.0434, 0.0044, 0.0395, 0.1287],\n",
       "        [0.0192, 0.0248, 0.0600, 0.0217, 0.0289, 0.7255, 0.0654, 0.0041, 0.0504],\n",
       "        [0.0135, 0.0151, 0.0969, 0.0252, 0.0040, 0.0789, 0.7203, 0.0303, 0.0159],\n",
       "        [0.0188, 0.0189, 0.0216, 0.0917, 0.0385, 0.0056, 0.0458, 0.6878, 0.0712],\n",
       "        [0.0067, 0.0191, 0.0221, 0.0272, 0.0760, 0.0299, 0.0150, 0.0632, 0.7408]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.softmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6a413c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0206, 0.0227, 0.6208, 0.0645, 0.0188, 0.0932, 0.1095, 0.0258, 0.0241],\n",
       "        [0.0240, 0.0221, 0.0461, 0.6261, 0.0809, 0.0169, 0.0320, 0.1275, 0.0243],\n",
       "        [0.0301, 0.0247, 0.0226, 0.0906, 0.6162, 0.0434, 0.0044, 0.0395, 0.1287],\n",
       "        [0.0192, 0.0248, 0.0600, 0.0217, 0.0289, 0.7255, 0.0654, 0.0041, 0.0504],\n",
       "        [0.0135, 0.0151, 0.0969, 0.0252, 0.0040, 0.0789, 0.7203, 0.0303, 0.0159],\n",
       "        [0.0188, 0.0189, 0.0216, 0.0917, 0.0385, 0.0056, 0.0458, 0.6878, 0.0712],\n",
       "        [0.0067, 0.0191, 0.0221, 0.0272, 0.0760, 0.0299, 0.0150, 0.0632, 0.7408]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.softmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f0b46ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.softmax(-1).argmax(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e018c51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 3, 4, 5, 6, 7, 8]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.softmax(-1).argmax(-1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "26fd1adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1, 2, 3, 4, 5, 6, 7]]), tensor([[2, 3, 4, 5, 6, 7, 8]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "construct_data(sentence, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed67a4eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f9fbddd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3, 4, 5, 6, 7, 8])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([[2, 3, 4, 5, 6, 7, 8]]).view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ee85e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
