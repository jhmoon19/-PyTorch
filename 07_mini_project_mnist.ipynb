{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "10b7fdab",
   "metadata": {},
   "source": [
    "# 미니프로젝트: 나만의 딥러닝 모델로 Mnist Dataset 학습하기\n",
    "## <0-9 숫자 손글씨 인식 문제>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503becc2",
   "metadata": {},
   "source": [
    "## 1. 패키지 불러오기 및 GUI 프로그램 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ecc80c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# matplotlib 패키지 결과물을 노트북 실행 \n",
    "# 브라우저 안에 보일 수 있게 하는 명령어\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# mnist 내장된 torchvision 패키지에서 데이터셋 불러오기\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# 손글씨 써볼 수 있는 GUI 프로그램\n",
    "\"\"\" 제공된 drawing.py 이용!! \"\"\"\n",
    "from drawing import Drawing\n",
    "# 그림 시각화 처리 패키지\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "def drawing_custom_number(preprocess, filepath=\"./figs\", return_img=True):\n",
    "    \"\"\" 손글씨 입력 GUI 미니 프로그램 \"\"\"\n",
    "    if (not os.path.isdir(\"figs\")) and (filepath == \"./figs\"):\n",
    "        os.mkdir(\"figs\")\n",
    "    draw = Drawing()\n",
    "    draw.main(preprocess=preprocess, filepath=filepath)\n",
    "    img = Image.open(draw.file)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()\n",
    "    if return_img:\n",
    "        return img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "253c2cc1",
   "metadata": {},
   "source": [
    "## 2. 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d90c589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target: 0\n",
      "Size of Image: (28, 28)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(70)\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', # 데이터 경로\n",
    "                              train=True,     # 훈련데이터 여부\n",
    "                              download=True,  # 기존에 없으면 root경로에 다운로드\n",
    "                              transform=transforms.ToTensor()) # 텐서로 바꾸는 전처리\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./data',\n",
    "                             train=False,\n",
    "                             transform=transforms.ToTensor())\n",
    "\n",
    "# 데이터 살펴보기: 훈련데이터 중 임의의 데이터 골라서 보여줌\n",
    "idx = torch.randint(0, len(train_dataset), (1,)).item()\n",
    "random_image = train_dataset[idx][0].squeeze().numpy()\n",
    "target_num = train_dataset[idx][1]\n",
    "print(\"Target: {}\".format(target_num))\n",
    "print(\"Size of Image: {}\".format(random_image.shape))\n",
    "plt.imshow(random_image, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6a47fa",
   "metadata": {},
   "source": [
    "## [MNIST Dataset]\n",
    "- 인공지능 연구 권위자 LeCun 교수님께서 만드심.\n",
    "- 딥러닝을 공부할 때 반드시 거쳐야하는 존재\n",
    "- 6만개의 학습데이터, 1만개의 검증데이터\n",
    "- 간단한 컴퓨터 비전 데이터 세트\n",
    "- 0~1 정규화된 28\\*28 픽셀, 중앙 정렬\n",
    "- 각 이미지는 평평하게 784 feature의 1D numpy 배열로 변환됨."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1088f2",
   "metadata": {},
   "source": [
    "## 3. 데이터로더 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd3f65b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 1, 28, 28])\n",
      "torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "BATCH = 64\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "STEP = 10\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                         batch_size=BATCH,\n",
    "                         shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                        batch_size=BATCH,\n",
    "                        shuffle=True)\n",
    "\n",
    "for (data, target) in train_loader:\n",
    "    print(data.size(), target.size(), sep='\\n')\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4261d493",
   "metadata": {},
   "source": [
    "## 4. 모델, 손실함수 및 옵티마이저 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "771e8e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.flatten = lambda x: x.view(x.size(0), -1)\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)        \n",
    "        self.linear3 = nn.Linear(hidden_size, output_size)        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.linear1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.linear3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7a1b37",
   "metadata": {},
   "source": [
    "### 4-1. 모델 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05068714",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net(input_size=28*28, hidden_size=100, output_size=10).to(DEVICE)\n",
    "# .to(DEVICE): 'cuda' 혹은 'cpu' 문자열을 모델에게 전달해서, GPU 사용 여부 결정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9286a8",
   "metadata": {},
   "source": [
    "### 4-2. 손실함수, 옵티마이저 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b9cea4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of parameters: 89610\n"
     ]
    }
   ],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "# 매개변수 개수 확인\n",
    "num_params = 0\n",
    "for params in model.parameters():\n",
    "    num_params += params.view(-1).size(0)\n",
    "print(\"Total number of parameters: {}\".format(num_params))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324c0dff",
   "metadata": {},
   "source": [
    "## 5. 학습 및 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80e68a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, loss_func, optimizer, step, device, print_step=200):\n",
    "    \"\"\" 1스텝 동안 발생하는 학습과정 \"\"\"\n",
    "    \n",
    "    # 모델에게 훈련단계라고 선언\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data,target) in enumerate(train_loader):\n",
    "        # 1) 입력과 타겟 텐서에 GPU 사용여부 전달\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # 2) 경사 초기화\n",
    "        model.zero_grad()\n",
    "        # 3) 순방향 전파\n",
    "        output = model(data)\n",
    "        # 4) 손실값 계산\n",
    "        loss = loss_func(output, target)\n",
    "        # 5) 역방향 전파\n",
    "        loss.backward()\n",
    "        # 6) 매개변수 업데이트\n",
    "        optimizer.step()\n",
    "        \n",
    "        # 중간과정 print\n",
    "        if batch_idx % print_step == 0:\n",
    "            print(\"Train Step: {} ({:05.2f}%)  \\tLoss: {:.4f}\".format(step,\n",
    "            100.*(batch_idx*train_loader.batch_size)/len(train_loader.dataset),\n",
    "                                                                loss.item()))\n",
    "            \n",
    "def test(model, test_loader, loss_func, device):\n",
    "    # 모델에게 평가단계라고 선언\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data,target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # 1) 순방향전파\n",
    "            output = model(data)\n",
    "            # 2) 손실 계산 (합)\n",
    "            test_loss += loss_func(output, target, reduction='sum').item()\n",
    "            # 3) 예측값에 해당하는 클래스 번호 반환\n",
    "            pred = output.softmax(1).argmax(dim=1, keepdim=True)\n",
    "            # 4) 정확하게 예측한 개수 기록\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_acc = correct / len(test_loader.dataset)\n",
    "    \n",
    "    print(\"Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:05.2f}%)\".format(\\\n",
    "        test_loss, correct, len(test_loader.dataset), 100.*test_acc))\n",
    "    \n",
    "    return test_loss, test_acc\n",
    "\n",
    "def main(model, train_loader, test_loader, loss_func, optimizer, n_step, device,\n",
    "        save_path=None, print_step=200):\n",
    "    \"\"\" 메인 학습 함수 \"\"\"\n",
    "    test_accs = []\n",
    "    best_acc = 0.0\n",
    "    \n",
    "    for step in range(1, n_step+1):\n",
    "        # 훈련\n",
    "        train(model, train_loader, loss_func, optimizer,\n",
    "             step=step, device=device, print_step=print_step)\n",
    "        # 평가\n",
    "        test_loss, test_acc = test(model, test_loader,\n",
    "                                  loss_func = F.cross_entropy,\n",
    "                                  device=device)\n",
    "        \n",
    "        # 테스트 정확도 기록\n",
    "        test_accs.append(test_acc)\n",
    "        \n",
    "        # 모델 최적의 매개변수값을 저장할지 결정하고, 기록\n",
    "        if len(test_accs) >= 2:\n",
    "            if test_acc >= best_acc:\n",
    "                best_acc = test_acc\n",
    "                best_state_dict = model.state_dict()\n",
    "                print(\"discard previous state, best model state saved!\")\n",
    "        print(\"\")\n",
    "        \n",
    "    # 매개변수 값 저장\n",
    "    if save_path is not None:\n",
    "        torch.save(best_state_dict, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afa8a69a",
   "metadata": {},
   "source": [
    "### 학습 시작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f6fd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Step: 1 (00.00%)  \tLoss: 2.3013\n",
      "Train Step: 1 (21.33%)  \tLoss: 0.2655\n",
      "Train Step: 1 (42.67%)  \tLoss: 0.3571\n",
      "Train Step: 1 (64.00%)  \tLoss: 0.2010\n",
      "Train Step: 1 (85.33%)  \tLoss: 0.2346\n",
      "Test set: Average loss: 0.1893, Accuracy: 9419/10000 (94.19%)\n",
      "\n",
      "Train Step: 2 (00.00%)  \tLoss: 0.0604\n",
      "Train Step: 2 (21.33%)  \tLoss: 0.1508\n",
      "Train Step: 2 (42.67%)  \tLoss: 0.0415\n",
      "Train Step: 2 (64.00%)  \tLoss: 0.0584\n",
      "Train Step: 2 (85.33%)  \tLoss: 0.2859\n",
      "Test set: Average loss: 0.1229, Accuracy: 9624/10000 (96.24%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 3 (00.00%)  \tLoss: 0.1770\n",
      "Train Step: 3 (21.33%)  \tLoss: 0.1353\n",
      "Train Step: 3 (42.67%)  \tLoss: 0.0814\n",
      "Train Step: 3 (64.00%)  \tLoss: 0.0401\n",
      "Train Step: 3 (85.33%)  \tLoss: 0.1208\n",
      "Test set: Average loss: 0.1033, Accuracy: 9685/10000 (96.85%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 4 (00.00%)  \tLoss: 0.0458\n",
      "Train Step: 4 (21.33%)  \tLoss: 0.0174\n",
      "Train Step: 4 (42.67%)  \tLoss: 0.1234\n",
      "Train Step: 4 (64.00%)  \tLoss: 0.0110\n",
      "Train Step: 4 (85.33%)  \tLoss: 0.1150\n",
      "Test set: Average loss: 0.0883, Accuracy: 9729/10000 (97.29%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 5 (00.00%)  \tLoss: 0.0094\n",
      "Train Step: 5 (21.33%)  \tLoss: 0.0074\n",
      "Train Step: 5 (42.67%)  \tLoss: 0.0414\n",
      "Train Step: 5 (64.00%)  \tLoss: 0.0267\n",
      "Train Step: 5 (85.33%)  \tLoss: 0.0172\n",
      "Test set: Average loss: 0.0841, Accuracy: 9743/10000 (97.43%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 6 (00.00%)  \tLoss: 0.0081\n",
      "Train Step: 6 (21.33%)  \tLoss: 0.1204\n",
      "Train Step: 6 (42.67%)  \tLoss: 0.0598\n",
      "Train Step: 6 (64.00%)  \tLoss: 0.0697\n",
      "Train Step: 6 (85.33%)  \tLoss: 0.0512\n",
      "Test set: Average loss: 0.0859, Accuracy: 9739/10000 (97.39%)\n",
      "\n",
      "Train Step: 7 (00.00%)  \tLoss: 0.0806\n",
      "Train Step: 7 (21.33%)  \tLoss: 0.0218\n",
      "Train Step: 7 (42.67%)  \tLoss: 0.0043\n",
      "Train Step: 7 (64.00%)  \tLoss: 0.0236\n",
      "Train Step: 7 (85.33%)  \tLoss: 0.0357\n",
      "Test set: Average loss: 0.0794, Accuracy: 9770/10000 (97.70%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 8 (00.00%)  \tLoss: 0.0170\n",
      "Train Step: 8 (21.33%)  \tLoss: 0.0087\n",
      "Train Step: 8 (42.67%)  \tLoss: 0.0561\n",
      "Train Step: 8 (64.00%)  \tLoss: 0.0202\n",
      "Train Step: 8 (85.33%)  \tLoss: 0.0234\n",
      "Test set: Average loss: 0.0834, Accuracy: 9767/10000 (97.67%)\n",
      "\n",
      "Train Step: 9 (00.00%)  \tLoss: 0.0133\n",
      "Train Step: 9 (21.33%)  \tLoss: 0.0345\n",
      "Train Step: 9 (42.67%)  \tLoss: 0.0068\n",
      "Train Step: 9 (64.00%)  \tLoss: 0.0019\n",
      "Train Step: 9 (85.33%)  \tLoss: 0.0034\n",
      "Test set: Average loss: 0.0824, Accuracy: 9782/10000 (97.82%)\n",
      "discard previous state, best model state saved!\n",
      "\n",
      "Train Step: 10 (00.00%)  \tLoss: 0.0158\n",
      "Train Step: 10 (21.33%)  \tLoss: 0.0048\n",
      "Train Step: 10 (42.67%)  \tLoss: 0.0219\n",
      "Train Step: 10 (64.00%)  \tLoss: 0.0598\n",
      "Train Step: 10 (85.33%)  \tLoss: 0.0034\n",
      "Test set: Average loss: 0.0904, Accuracy: 9754/10000 (97.54%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main(model=model,\n",
    "    train_loader=train_loader,\n",
    "    test_loader=test_loader,\n",
    "    loss_func=loss_function,\n",
    "    optimizer=optimizer,\n",
    "    n_step=STEP,\n",
    "    device=DEVICE,\n",
    "    save_path=\"mnist_model.pt\",\n",
    "    print_step=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f11df2",
   "metadata": {},
   "source": [
    "# 6. 내가 그린 손글씨로 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e41fd130",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file saved ./figs\\num_img.png\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = drawing_custom_number(preprocess=True, return_img=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b39b7db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted number is 5.\n"
     ]
    }
   ],
   "source": [
    "# 내가 그린 이미지를 (1,28,28) 크기 텐서로 바꿔줌\n",
    "test_input = torch.Tensor(np.array(img)).unsqueeze(0).to(DEVICE)\n",
    "pred = model(test_input)\n",
    "print(\"Predicted number is {}.\".format(pred.softmax(1).argmax().item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c8b2f3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -955.0872, -1143.5399,  -857.5981,   250.9672, -1120.6174,   597.0349,\n",
       "         -1418.8156,  -919.2238,    23.1948,   453.6948]],\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "da36133c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.softmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "84d631c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAy0lEQVR4nGNgGDaAEUqLKrNJizD//3zm1eu/GJIlcu9fffz+j09L6tvdQzc+QARZoJICcy5BWcraYb/rf6BIMvHDzLp7dxP7L1SdbyWQHPITpgNKvxLF4lqYzpud8lz/39489AybVzisf79hVtDUvzf1BRYjoGoCpqrjlGRgUJqjgkfWYDbMKrhrEeDifxU0ScFUVpjI/ydKaJKf/raLQEX4FeDegZvvEX7+2P0/IpJatptXYUgyiPkbsP9jeXV37z3sDuXiweMLOgEATCc8EHmNU2YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
